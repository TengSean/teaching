{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標題\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## 目錄\n",
    "- 介紹\n",
    "- 下載\n",
    "- 如何翠取出想要的資料\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載BeautifulSoup Selenium ( Anaconda )\n",
    "<br>\n",
    "請透過下列指令安裝BeautifulSoup跟Selenium的模組\n",
    "<br><br>\n",
    "<br>\n",
    "注意：若以下指令有問題的話就把指令（不包含驚嘆號的部份）複製到終端機上執行 （eg: conda install -yc anaconda beautifulsoup4）\n",
    "<br><br>\n",
    "<em><bold>PS: 若已經安裝過可跳過這個階段跳到實做的部份。</bold></em>\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T13:16:47.968552Z",
     "start_time": "2020-08-09T13:03:31.573609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab==1.1.4=pyhf63ae98_0\n",
      "  - conda-forge/linux-64::jupyter_highlight_selected_word==0.2.0=py37_1000\n",
      "  - defaults/linux-64::jupyter_client==5.3.3=py37_1\n",
      "  - defaults/linux-64::r-essentials==3.6.0=r36_0\n",
      "  - conda-forge/linux-64::jupyter_contrib_nbextensions==0.5.1=py37_0\n",
      "  - defaults/linux-64::jupyter==1.0.0=py37_7\n",
      "  - defaults/linux-64::spyder-kernels==0.5.2=py37_0\n",
      "  - defaults/noarch::distributed==2.5.2=py_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - conda-forge/linux-64::jupyter_latex_envs==1.4.4=py37_1000\n",
      "  - defaults/linux-64::terminado==0.8.2=py37_0\n",
      "  - defaults/linux-64::jupyter_console==6.0.0=py37_0\n",
      "  - defaults/linux-64::notebook==6.0.1=py37_0\n",
      "  - defaults/linux-64::scikit-image==0.15.0=py37he6710b0_0\n",
      "  - conda-forge/linux-64::jupyter_nbextensions_configurator==0.4.1=py37_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::matplotlib==3.1.1=py37h5429711_0\n",
      "  - defaults/linux-64::anaconda==2019.10=py37_0\n",
      "  - defaults/linux-64::ipykernel==5.1.2=py37h39e3cac_0\n",
      "  - defaults/linux-64::spyder==3.3.6=py37_0\n",
      "  - defaults/noarch::anaconda-project==0.8.3=py_0\n",
      "  - defaults/linux-64::bokeh==1.3.4=py37_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py37_0\n",
      "  - defaults/linux-64::seaborn==0.9.0=py37_0\n",
      "  - conda-forge/noarch::jupyter_contrib_core==0.3.3=py_2\n",
      "  - defaults/noarch::qtconsole==4.5.5=py_0\n",
      "  - defaults/linux-64::_ipyw_jlab_nb_ext_conf==0.1.0=py37_0\n",
      "  - defaults/noarch::dask==2.5.2=py_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab==1.1.4=pyhf63ae98_0\n",
      "  - conda-forge/linux-64::jupyter_highlight_selected_word==0.2.0=py37_1000\n",
      "  - defaults/linux-64::jupyter_client==5.3.3=py37_1\n",
      "  - defaults/linux-64::r-essentials==3.6.0=r36_0\n",
      "  - conda-forge/linux-64::jupyter_contrib_nbextensions==0.5.1=py37_0\n",
      "  - defaults/linux-64::jupyter==1.0.0=py37_7\n",
      "  - defaults/linux-64::spyder-kernels==0.5.2=py37_0\n",
      "  - defaults/noarch::distributed==2.5.2=py_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - conda-forge/linux-64::jupyter_latex_envs==1.4.4=py37_1000\n",
      "  - defaults/linux-64::terminado==0.8.2=py37_0\n",
      "  - defaults/linux-64::jupyter_console==6.0.0=py37_0\n",
      "  - defaults/linux-64::notebook==6.0.1=py37_0\n",
      "  - defaults/linux-64::scikit-image==0.15.0=py37he6710b0_0\n",
      "  - conda-forge/linux-64::jupyter_nbextensions_configurator==0.4.1=py37_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::matplotlib==3.1.1=py37h5429711_0\n",
      "  - defaults/linux-64::anaconda==2019.10=py37_0\n",
      "  - defaults/linux-64::ipykernel==5.1.2=py37h39e3cac_0\n",
      "  - defaults/linux-64::spyder==3.3.6=py37_0\n",
      "  - defaults/noarch::anaconda-project==0.8.3=py_0\n",
      "  - defaults/linux-64::bokeh==1.3.4=py37_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py37_0\n",
      "  - defaults/linux-64::seaborn==0.9.0=py37_0\n",
      "  - conda-forge/noarch::jupyter_contrib_core==0.3.3=py_2\n",
      "  - defaults/noarch::qtconsole==4.5.5=py_0\n",
      "  - defaults/linux-64::_ipyw_jlab_nb_ext_conf==0.1.0=py37_0\n",
      "  - defaults/noarch::dask==2.5.2=py_0\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/sean/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - beautifulsoup4\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    anaconda-custom            |           py37_0           6 KB  anaconda\n",
      "    beautifulsoup4-4.9.1       |           py37_0         162 KB  anaconda\n",
      "    certifi-2020.6.20          |           py37_0         159 KB  anaconda\n",
      "    tornado-6.0.4              |   py37h7b6447c_1         649 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         977 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  tornado            anaconda/linux-64::tornado-6.0.4-py37h7b6447c_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  beautifulsoup4     pkgs/main::beautifulsoup4-4.8.0-py37_0 --> anaconda::beautifulsoup4-4.9.1-py37_0\n",
      "  ca-certificates    pkgs/main::ca-certificates-2019.8.28-0 --> anaconda::ca-certificates-2020.6.24-0\n",
      "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> anaconda::certifi-2020.6.20-py37_0\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_2 --> anaconda::openssl-1.1.1g-h7b6447c_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  anaconda               pkgs/main::anaconda-2019.10-py37_0 --> anaconda::anaconda-custom-py37_0\n",
      "  conda              conda-forge::conda-4.8.3-py37hc8dfbb8~ --> anaconda::conda-4.8.3-py37_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "tornado-6.0.4        | 649 KB    | ##################################### | 100% \n",
      "certifi-2020.6.20    | 159 KB    | ##################################### | 100% \n",
      "anaconda-custom      | 6 KB      | ##################################### | 100% \n",
      "beautifulsoup4-4.9.1 | 162 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/sean/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - selenium\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2020.6.20          |   py37hc8dfbb8_0         151 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         151 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                        anaconda::conda-4.8.3-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
      "  openssl               anaconda::openssl-1.1.1g-h7b6447c_0 --> conda-forge::openssl-1.1.1g-h516909a_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     anaconda::ca-certificates-2020.6.24-0 --> conda-forge::ca-certificates-2020.6.20-hecda079_0\n",
      "  certifi                anaconda::certifi-2020.6.20-py37_0 --> conda-forge::certifi-2020.6.20-py37hc8dfbb8_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2020.6.20    | 151 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -yc anaconda beautifulsoup4\n",
    "\n",
    "!conda install -yc conda-forge selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-09T09:54:28.687660Z",
     "start_time": "2020-08-09T09:54:28.680000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful version: 4.8.0\n",
      "Selenium version: 3.141.0\n"
     ]
    }
   ],
   "source": [
    "import bs4 \n",
    "import selenium\n",
    "\n",
    "bs4_version = bs4.__version__\n",
    "sele_version = selenium.__version__\n",
    "\n",
    "print(f\"Beautiful version: {bs4_version}\")\n",
    "print(f\"Selenium version: {sele_version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "OK 那摸環境的配置好了，\n",
    "<br>\n",
    "<br>\n",
    "下面的例子將為我們往後練習作使用，先跑跑看下面的code並檢查輸出為何\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T04:48:23.612363Z",
     "start_time": "2020-08-10T04:48:23.593561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html><head><title>The Dormouse's story</title></head><body><p class=\"title\"><b>The Dormouse's story</b></p><p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p><a class=\"brother\" href=\"http://example.com/tillie\" id=\"link4\">\n",
      "    Tillie\n",
      "   </a><p class=\"story\">...</p>\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "html_sample = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head><body><p class=\"title\"><b>The Dormouse's story</b></p><p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p><a class=\"brother\" href=\"http://example.com/tillie\" id=\"link4\">joseph</a><p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs(html_sample, 'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "看得出來輸出的格式是跟我們餵給他的資料有關\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "但是我們知道html的排版其實是有規律的，是一種巢狀迴圈的概念。\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "將輸出進行排版有助於我們檢查結果，整體而言是可以提高我們codint效率的一個技巧，\n",
    "<br>\n",
    "<br>\n",
    "幸運地，Beautiful有提供一個方法叫 prettify()\n",
    "<br>\n",
    "<br>\n",
    "這個方法來能使輸出變得漂亮些，那摸請跑跑看下面的程式碼看排版後的結果如何。\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T04:48:26.970235Z",
     "start_time": "2020-08-10T04:48:26.962463Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ;\n",
      "and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <a class=\"brother\" href=\"http://example.com/tillie\" id=\"link4\">\n",
      "   Tillie\n",
      "  </a>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# 透過prettify()指令將輸出作排版以便閱讀\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "緊接著要來對我們的html_sampl進行分析，再看看幾個比較基本的指令前先讓我們看看html的格式長怎樣。\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    " ![tag.png source: ./src/tag ](./src/tag.png)\n",
    "<br><br>\n",
    "<em>TagName:</em> 顧名思義就是標籤的名稱，一個網站是由許多標籤鎖組成，標籤與標籤彼此存在著從屬關係且又根據特定規則而來列著。<br><br>\n",
    "<em>Attribute:</em> 用於修飾tag，如對齊、長寬、賦予id及class等等<br><br>\n",
    "<italic><em>HINT:</em></italic> class跟id的公用通常與css密不可分，css是一種用來為結構化文件（如HTML文件或XML應用）添加樣式（字型、間距和顏色等）的電腦語言(取自維基)<br><br>\n",
    "Content: 顯示於網頁的內容<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T04:53:36.866043Z",
     "start_time": "2020-08-10T04:53:36.824436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title tag: <title>The Dormouse's story</title>\n",
      "\n",
      "Type: <class 'bs4.element.Tag'>\n",
      "__________________________________________________ \n",
      "\n",
      "Ttile tag name: title\n",
      "\n",
      "Type: <class 'str'>\n",
      "__________________________________________________ \n",
      "\n",
      "Title string: The Dormouse's story\n",
      "\n",
      "Type: <class 'bs4.element.NavigableString'>\n",
      "__________________________________________________ \n",
      "\n",
      "Title parent name: head\n",
      "\n",
      "Type: <class 'str'>\n",
      "__________________________________________________ \n",
      "\n",
      "P tag: <p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "Type: <class 'bs4.element.Tag'>\n",
      "__________________________________________________ \n",
      "\n",
      "P class: ['title']\n",
      "\n",
      "Type: <class 'list'>\n",
      "__________________________________________________ \n",
      "\n",
      "a tag: <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "\n",
      "Type: <class 'bs4.element.Tag'>\n",
      "__________________________________________________ \n",
      "\n",
      "All a tag: [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, <a class=\"brother\" href=\"http://example.com/tillie\" id=\"link4\">\n",
      "    Tillie\n",
      "   </a>]\n",
      "\n",
      "Type: <class 'bs4.element.ResultSet'>\n",
      "__________________________________________________ \n",
      "\n",
      "ID = link3: <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "\n",
      "Type: <class 'bs4.element.Tag'>\n",
      "__________________________________________________ \n",
      "\n",
      "All a and class = brother: [<a class=\"brother\" href=\"http://example.com/tillie\" id=\"link4\">\n",
      "    Tillie\n",
      "   </a>]\n",
      "Type: <class 'bs4.element.ResultSet'>\n",
      "__________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 取得 title 的 'tag'\n",
    "title_tag = soup.title\n",
    "print(f'Title tag: {title_tag}', end='\\n\\n')\n",
    "print(f\"Type: {type(title_tag)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "\n",
    "# 取得 title tag 的 'tag名稱'\n",
    "title_tag_name = soup.title.name\n",
    "print(f\"Ttile tag name: {title_tag_name}\", end='\\n\\n')\n",
    "print(f\"Type: {type(title_tag_name)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "# 取得 title tag 的 '內容'\n",
    "title_string = soup.title.string\n",
    "print(f\"Title string: {title_string}\", end='\\n\\n')\n",
    "print(f\"Type: {type(title_string)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "\n",
    "# 取得 title tag 的 '父tag的tag名稱'\n",
    "title_parent_name = soup.title.parent.name\n",
    "print(f\"Title parent name: {title_parent_name}\", end='\\n\\n')\n",
    "print(f\"Type: {type(title_parent_name)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "\n",
    "# 取得 p tag 的 'tag'\n",
    "p_tag = soup.p\n",
    "print(f\"P tag: {p_tag}\", end='\\n\\n')\n",
    "print(f\"Type: {type(p_tag)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "\n",
    "# 取得 p tag 的 '名為class得屬性'\n",
    "p_class = soup.p['class']\n",
    "print(f\"P class: {p_class}\", end='\\n\\n')\n",
    "print(f\"Type: {type(p_class)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "# 取得 a tag 得 'tag'\n",
    "a_tag = soup.a\n",
    "print(f\"a tag: {a_tag}\", end='\\n\\n')\n",
    "print(f\"Type: {type(a_tag)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "\n",
    "# 取得 '所有 a tag'\n",
    "all_a_tag = soup.find_all('a')\n",
    "print(f\"All a tag: {all_a_tag}\", end='\\n\\n')\n",
    "print(f\"Type: {type(all_a_tag)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "# 取得 '屬性id為link3' 的 tag\n",
    "id_link3 = soup.find(id=\"link3\")\n",
    "print(f\"ID = link3: {id_link3}\", end='\\n\\n')\n",
    "print(f\"Type: {type(id_link3)}\")\n",
    "print('_'*50, '\\n')\n",
    "\n",
    "\n",
    "a_class_brother = soup.find_all('a', {'class': 'brother'})\n",
    "print(f\"All a and class = brother: {a_class_brother}\")\n",
    "print(f\"Type: {type(a_class_brother)}\")\n",
    "print('_'*50, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "由上面可知，當我們用soup.find()跟soup.p這兩種指令時會發現它只會回傳一個結果，<br><br>\n",
    "\n",
    "但當我們用soup.find_all()時會回傳一個所有並用list包起來的串列。<br><br>\n",
    "\n",
    "很明顯，後者會是我們比較常用的方式，因為往往我們爬的資料都是很大量的例如一個表格或是大量的圖片等等。<br><br>\n",
    "也確實，我個人在使用爬蟲軟體時也都是使用find_all()這個方法來完成的。<br><br>\n",
    "至於要爬哪些標籤？又要爬什摸屬性？這就是爬從麻煩且費時的地方。<br><br>\n",
    "目前我個人是使用chrome的檢查網頁原始碼的方式(F12)來看網站上有哪些東西是我想要跟不想要的。<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "由上面可當你要找所有的tag時會用到find_all指令，find_all是一個很強大的指令，\n",
    "<br><br>\n",
    "它可以根據你給他的參數去找到你想要的tag，然而這也是我們再做數據分析時常用到的指令，\n",
    "<br><br>\n",
    "只要知道你想要的tag在哪裡屬性是什摸，都可以透過find_all指令來快速達成你的目的。\n",
    "<br>\n",
    "<br>\n",
    "以下表格列出幾個常用的tag以及我們爬蟲時常會用到的attribute<br><br><br>\n",
    "\n",
    "\n",
    " ![tag.png source: ./src/table ](./src/table.png) \n",
    " <br>\n",
    " <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_test = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head><body><p class=\"title\"><b>The Dormouse's story</b></p><p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p><p class=\"story\">...</p>\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
